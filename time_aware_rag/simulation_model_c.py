import os
import sys
import json
import pandas as pd
import random
from openai import OpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from utils.persona_generator import generate_balanced_personas, Persona
from utils.search_queries import GAMER_TYPE_QUERIES, GENERAL_QUERY
from utils.llm_config import get_llm_client, TEMPERATURE
from time_aware_rag.rag_modules import RAGRetriever

# 1. LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)
client, MODEL_NAME = get_llm_client()
print(f"âœ… Using model: {MODEL_NAME} (Team 3)")

OUTPUT_FILE = "time_aware_rag/Team3_TimeAware_Results_Final.csv"
SIMULATION_DATES_FILE = "datasets/simulation_dates.csv"

# =============================================================================
# 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
# =============================================================================

def create_prompt(agent: Persona, current_date: str, context: list):
    context_str = "\n".join(context) if context else "(No reviews found.)"
    
    return f"""[ROLE]
You are a {agent.age} {agent.gender}.
Personality: '{agent.gamer_type_name_display}' ({agent.description})

[DATE]
Today is {current_date}.

[SEARCH RESULTS]
Reviews selected based on your interests and recentness (Time-Weighted):
{context_str}

[TASK]
Decide to buy 'Cyberpunk 2077' or not based strictly on the reviews above.
- The reviews are filtered by relevance and recency.
- Trust these reviews as the most important information available to you.

[OUTPUT]
JSON only:
{{
    "decision": "YES" or "NO",
    "reasoning": "Explain why based on the reviews."
}}
"""

# =============================================================================
# 3. API í˜¸ì¶œ
# =============================================================================

def call_llm(prompt: str) -> dict:
    try:
        res = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "system", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=TEMPERATURE
        )
        return json.loads(res.choices[0].message.content)
    except Exception as e:
        print(f"Error: {e}")
        return {"decision": "NO", "reasoning": "Error"}

# =============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ (Main Execution)
# =============================================================================

def run_experiment_b_rag(n_per_type: int = 13):
    print("=" * 70)
    print(f"Task 3: Time Aware Rag Simulation")
    print("=" * 70)

    # RAG ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    print("Initializing RAG Retriever...")
    retriever = RAGRetriever()

    # ë‚ ì§œ ë¡œë“œ
    dates_df = pd.read_csv(SIMULATION_DATES_FILE)
    simulation_dates = dates_df['date'].tolist()
    
    # ì—ì´ì „íŠ¸ ìƒì„±
    # README: "generate_balanced_personas(n_per_type=13)" (ì´ 104ëª…)
    personas = generate_balanced_personas(n_per_type=n_per_type) 
    print(f"Generated {len(personas)} agents.")

    results = []
    
    # ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
    total_steps = len(simulation_dates) * len(personas)
    step_count = 0

    for date_str in simulation_dates:
        print(f"\nğŸ“… Date: {date_str}")
        
        for persona in personas:
            step_count += 1
            # 1. ì¿¼ë¦¬ ì„ ì • (Team 3 ë°©ì‹: 4ê°œ ëœë¤ + ì¼ë°˜ ì¿¼ë¦¬)
            agent_queries = GAMER_TYPE_QUERIES.get(persona.gamer_type, [])
            selected_queries = []
            if len(agent_queries) >= 4:
                selected_queries = random.sample(agent_queries, 4)
            else:
                selected_queries = agent_queries # Fallback
            selected_queries.append(GENERAL_QUERY)
            
            # 2. ê²€ìƒ‰ (Team 3 Time-Aware ë¡œì§)
            # ì¿¼ë¦¬ë‹¹ 100ê°œë¥¼ ê²€ìƒ‰ í›„ ì‹œê°„ ê°ì‡ (Time-Decay) ë­í‚¹ì„ ì ìš©
            # Team 2ì™€ì˜ ì°¨ì´: similarity Ã— time_factorë¡œ ì¬ë­í‚¹
            
            # Persona ê°ì²´ì— search_queries ì†ì„± ì¶”ê°€ (rag_modules.py í˜¸í™˜)
            # ë…¸íŠ¸ë¶ì˜ ChromaEnsembleRetriever.retrieve_weighted() ë¡œì§ê³¼ ë™ì¼
            class PersonaWithQueries:
                def __init__(self, persona, queries):
                    self.search_queries = queries
            
            persona_with_queries = PersonaWithQueries(persona, selected_queries)
            
            # Time-Aware RAG ê²€ìƒ‰ (similarity Ã— time_factor)
            # ë…¸íŠ¸ë¶ì˜ retrieve_weighted() ë©”ì„œë“œì™€ ë™ì¼í•œ ë¡œì§
            final_docs = retriever.retrieve_reviews(
                persona_with_queries,
                current_date_str=date_str,
                top_k_final=5,
                decay_rate=0.01  # Half-life â‰ˆ 70ì¼
            )
            
            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = create_prompt(persona, date_str, final_docs)
            
            # 4. LLM í˜¸ì¶œ
            print(f"[{step_count}/{total_steps}] {persona.gamer_type_name_display}...", end=" ", flush=True)
            res = call_llm(prompt)
            
            decision = res.get("decision", "NO").upper()
            decision = "YES" if "YES" in decision else "NO"
            
            print(f"-> {decision}")
            
            results.append({
                "Agent_ID": persona.id,
                "Name": persona.name,
                "Persona_Type": persona.gamer_type_name_display,
                "Decision": decision,
                "Simulation_Date": date_str,
                "Reasoning": res.get("reasoning", "")
            })

    # ê²°ê³¼ ì €ì¥
    df = pd.DataFrame(results)
    df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    
    # ìµœì¢… í†µê³„ ì¶œë ¥
    decision_counts = df['Decision'].value_counts(normalize=True)
    
    print("\n" + "=" * 70)
    print("Decision")
    print(f"NO     {decision_counts.get('NO', 0):.3f}")
    print(f"YES    {decision_counts.get('YES', 0):.3f}")
    print("=" * 70)
    print(f"Simulation completed. Results saved to {OUTPUT_FILE}")
    print("=" * 70)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìœ í˜•ë³„ 1ëª… ìƒì„±)
    run_experiment_b_rag(n_per_type=13)
